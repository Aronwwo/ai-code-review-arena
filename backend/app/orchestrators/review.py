"""Review orchestrator for conducting multi-agent code reviews."""
import asyncio
import json
import hashlib
import logging
from datetime import datetime, timezone
from sqlmodel import Session, select, func
from pydantic import BaseModel, ValidationError
from app.models.project import Project
from app.models.file import File
from app.models.review import Review, ReviewAgent, Issue, Suggestion, IssueSeverity, AgentConfig
from app.providers.base import LLMMessage
from app.providers.router import provider_router, CustomProviderConfig
from app.utils.cache import cache
from app.utils.websocket import ws_manager
from app.config import settings

logger = logging.getLogger(__name__)


class IssueSchema(BaseModel):
    """Schema for parsing issue from LLM response."""
    severity: IssueSeverity
    category: str
    title: str
    description: str
    file_name: str | None = None
    line_start: int | None = None
    line_end: int | None = None
    suggested_fix: str | None = None


class ReviewResponseSchema(BaseModel):
    """Schema for parsing review response from LLM."""
    issues: list[IssueSchema]
    summary: str | None = None


class ReviewOrchestrator:
    """Orchestrates multi-agent code reviews."""

    AGENT_PROMPTS = {
        "general": """Jeste≈õ ekspertem ds. przeglƒÖd√≥w kodu, skupiajƒÖcym siƒô na og√≥lnej jako≈õci kodu i najlepszych praktykach.

Twoje obowiƒÖzki:
- Identyfikuj b≈Çƒôdy i b≈Çƒôdy logiczne
- Sprawdzaj ≈Çatwo≈õƒá konserwacji i czytelno≈õƒá kodu
- Oceniaj obs≈Çugƒô b≈Çƒôd√≥w i przypadki brzegowe
- Oceniaj organizacjƒô i strukturƒô kodu
- Sprawdzaj kompletno≈õƒá dokumentacji

Analizuj kod z krytycznym, ale konstruktywnym podej≈õciem.
Odpowiadaj kr√≥tko, rzeczowo i tylko w ramach tej roli.

WA≈ªNE: Preferuj jƒôzyk polski; je≈õli nie mo≈ºesz, u≈ºyj angielskiego. Dbaj o szybkie odpowiedzi i ograniczaj d≈Çugo≈õƒá.""",

        "security": """Jeste≈õ ekspertem ds. bezpiecze≈Ñstwa, skupiajƒÖcym siƒô na identyfikacji luk w zabezpieczeniach.

Twoje obowiƒÖzki:
- Identyfikuj luki injection (SQL, XSS, command injection)
- Sprawdzaj b≈Çƒôdy uwierzytelniania i autoryzacji
- PrzeglƒÖdaj u≈ºycie kryptografii
- Wykrywaj nara≈ºenie wra≈ºliwych danych
- Identyfikuj niebezpieczne konfiguracje
- Sprawdzaj znane podatne zale≈ºno≈õci

BƒÖd≈∫ dok≈Çadny i ostro≈ºny - bezpiecze≈Ñstwo jest kluczowe.
Odpowiadaj kr√≥tko, rzeczowo i tylko w ramach tej roli.

WA≈ªNE: Preferuj jƒôzyk polski; je≈õli nie mo≈ºesz, u≈ºyj angielskiego. Dbaj o szybkie odpowiedzi i ograniczaj d≈Çugo≈õƒá.""",

        "performance": """Jeste≈õ ekspertem ds. wydajno≈õci, skupiajƒÖcym siƒô na mo≈ºliwo≈õciach optymalizacji.

Twoje obowiƒÖzki:
- Identyfikuj nieefektywno≈õƒá algorytmicznƒÖ (O(n¬≤) gdzie mo≈ºliwe O(n))
- Wykrywaj problemy N+1 zapyta≈Ñ
- PrzeglƒÖdaj wzorce u≈ºycia pamiƒôci
- Sprawdzaj niepotrzebne obliczenia
- Identyfikuj operacje blokujƒÖce, kt√≥re mog≈Çyby byƒá async
- PrzeglƒÖdaj mo≈ºliwo≈õci cache'owania

Skup siƒô na mierzalnym wp≈Çywie na wydajno≈õƒá.
Odpowiadaj kr√≥tko, rzeczowo i tylko w ramach tej roli.

WA≈ªNE: Preferuj jƒôzyk polski; je≈õli nie mo≈ºesz, u≈ºyj angielskiego. Dbaj o szybkie odpowiedzi i ograniczaj d≈Çugo≈õƒá.""",

        "style": """Jeste≈õ recenzentem stylu kodu, skupiajƒÖcym siƒô na sp√≥jno≈õci i konwencjach.

Twoje obowiƒÖzki:
- Sprawdzaj konwencje nazewnictwa
- PrzeglƒÖdaj formatowanie kodu
- Weryfikuj standardy dokumentacji
- Sprawdzaj sp√≥jne wzorce
- Identyfikuj code smells
- PrzeglƒÖdaj type hints i adnotacje

Utrzymuj wysokie standardy jako≈õci i sp√≥jno≈õci kodu.
Odpowiadaj kr√≥tko, rzeczowo i tylko w ramach tej roli.

WA≈ªNE: Preferuj jƒôzyk polski; je≈õli nie mo≈ºesz, u≈ºyj angielskiego. Dbaj o szybkie odpowiedzi i ograniczaj d≈Çugo≈õƒá."""
    }

    MODERATOR_PROMPT = """Jeste≈õ Moderatorem przeglƒÖdu kodu. Twoim zadaniem jest TYLKO sformatowaƒá odpowiedzi od agent√≥w-ekspert√≥w w czytelny raport.

UWAGA: Agenci oznaczeni jako [BRAK ODPOWIEDZI] nie odpowiedzieli w wyznaczonym czasie lub wystƒÖpi≈Ç b≈ÇƒÖd - IGNORUJ ich ca≈Çkowicie.

KRYTYCZNE ZASADY:
- Twoim zadaniem jest TYLKO sformatowaƒá i zsyntetyzowaƒá odpowiedzi od agent√≥w, kt√≥rzy odpowiedzieli
- NIE generuj w≈Çasnej analizy kodu - opieraj siƒô TYLKO na odpowiedziach od agent√≥w
- Je≈õli NIE MA ≈ºadnych odpowiedzi od agent√≥w, zwr√≥ƒá: {"summary": "Nie mo≈ºna oceniƒá kodu - brak odpowiedzi od agent√≥w", "issues": [], "overall_quality": "Ocena og√≥lna: nie mo≈ºna oceniƒá"}
- NIE oceniaj kodu negatywnie tylko dlatego, ≈ºe niekt√≥rzy agenci nie odpowiedzieli
- Je≈õli agenci nie znale≈∫li problem√≥w, ocena powinna byƒá "dobry" lub "≈õwietny", NIE "wymaga poprawy"

Twoim zadaniem jest:
1. Przeanalizowaƒá odpowiedzi wszystkich agent√≥w, kt√≥rzy odpowiedzieli (opr√≥cz tych z [BRAK ODPOWIEDZI])
2. Stworzyƒá JEDEN ko≈Ñcowy raport, kt√≥ry syntetyzuje wszystkie znalezione problemy
3. UsunƒÖƒá duplikaty i podsumowaƒá najwa≈ºniejsze kwestie
4. Oceniƒá og√≥lnƒÖ jako≈õƒá kodu na podstawie TYLKO dostƒôpnych odpowiedzi

Odpowiedz TYLKO w formacie JSON (bez ≈ºadnego dodatkowego tekstu, bez markdown code blocks):
{
  "summary": "Twoje podsumowanie przeglƒÖdu kodu po polsku (2-3 zdania)",
  "issues": [
    {
      "severity": "info",
      "category": "security",
      "title": "Tytu≈Ç problemu po polsku",
      "description": "Opis problemu po polsku",
      "file_name": "nazwa_pliku.ext",
      "line_start": 10,
      "line_end": 15,
      "code_snippet": "fragment kodu",
      "suggested_fix": "Sugestia poprawki po polsku"
    }
  ],
  "overall_quality": "Ocena og√≥lna: ≈õwietny / dobry / wymaga poprawy / s≈Çaby"
}

WA≈ªNE - FORMATOWANIE ODPOWIEDZI:
- Formatuj TYLKO odpowiedzi od agent√≥w - NIE generuj w≈Çasnej analizy
- Zbierz problemy TYLKO z odpowiedzi agent√≥w (zignoruj [BRAK ODPOWIEDZI])
- Usu≈Ñ duplikaty i zsyntetyzuj podobne problemy
- Je≈õli w odpowiedziach agent√≥w nie ma problem√≥w, zwr√≥ƒá: {"summary": "Kod jest poprawny, nie znaleziono problem√≥w", "issues": [], "overall_quality": "Ocena og√≥lna: dobry"}
- Je≈õli sƒÖ problemy w odpowiedziach agent√≥w, u≈ºyj oceny: "dobry" (drobne), "wymaga poprawy" (≈õrednie), "s≈Çaby" (powa≈ºne)
- NIE dodawaj w≈Çasnych problem√≥w - TYLKO te z odpowiedzi agent√≥w
- Wszystkie teksty po polsku
- Zwr√≥ƒá TYLKO JSON, bez markdown, bez ```json ani ```"""

    def __init__(self, session: Session):
        """Initialize review orchestrator.

        Args:
            session: Database session
        """
        self.session = session

    async def conduct_review(
        self,
        review_id: int,
        provider_name: str | None = None,
        model: str | None = None,
        api_keys: dict[str, str] | None = None,
        agent_configs: dict[str, AgentConfig] | None = None,
        moderator_config: dict | None = None
    ) -> Review:
        """Przeprowad≈∫ code review u≈ºywajƒÖc wielu agent√≥w AI.

        Uproszczony flow dla obu tryb√≥w (council/arena):
        1. Ka≈ºdy agent daje JEDNƒÑ odpowied≈∫ (z konfigurowlnym timeout)
        2. Moderator syntetyzuje wszystkie odpowiedzi w jeden raport
        3. Agenci z timeout sƒÖ oznaczani i ignorowani przez moderatora

        Args:
            review_id: ID review do przeprowadzenia
            provider_name: Provider LLM (opcjonalny fallback)
            model: Nazwa modelu (opcjonalny fallback)
            api_keys: Klucze API per provider: {provider_name: api_key}
            agent_configs: Konfiguracja per agent: {role: AgentConfig} z timeout_seconds
            moderator_config: Konfiguracja moderatora

        Returns:
            Uko≈Ñczony obiekt Review ze statusem 'completed' lub 'failed'
        """
        # Pobierz review i projekt
        review = self.session.get(Review, review_id)
        if not review:
            raise ValueError(f"Review {review_id} nie istnieje")

        project = self.session.get(Project, review.project_id)
        if not project:
            raise ValueError(f"Project {review.project_id} nie istnieje")

        review_mode = review.review_mode or "council"
        logger.info(f"Review {review_id}: tryb {review_mode.upper()}")

        # Update review status
        review.status = "running"
        self.session.add(review)
        self.session.commit()

        try:
            # Get agents for this review
            agents_query = select(ReviewAgent).where(ReviewAgent.review_id == review_id)
            agents_list = self.session.exec(agents_query).all()

            # Send review started event
            agent_roles = [agent.role for agent in agents_list]
            await ws_manager.send_review_started(review_id, agent_roles)

            # Normalize configs
            typed_agent_configs: dict[str, AgentConfig] = {}
            if agent_configs:
                for role, config in agent_configs.items():
                    typed_agent_configs[role] = config if isinstance(config, AgentConfig) else AgentConfig(**config)

            typed_moderator_config = None
            if moderator_config:
                typed_moderator_config = (
                    moderator_config
                    if isinstance(moderator_config, AgentConfig)
                    else AgentConfig(**moderator_config)
                )

            # === KROK 1: Uruchom wszystkich agent√≥w SEKWENCYJNIE (jeden po drugim) ===
            # WA≈ªNE: Kolejny agent uruchamia siƒô DOPIERO po otrzymaniu odpowiedzi od poprzedniego
            # To zapobiega rate limiting i zapewnia stabilno≈õƒá, gdy agenci u≈ºywajƒÖ tego samego API key
            agent_responses: dict[str, str | None] = {}

            for idx, agent in enumerate(agents_list):
                logger.info(f"ü§ñ [{idx + 1}/{len(agents_list)}] Uruchamiam agenta {agent.role}...")
                
                # Get agent config if available
                agent_config = typed_agent_configs.get(agent.role)

                # Use agent's provider/model if configured
                agent_provider = agent.provider if agent.provider != "mock" else (provider_name or agent.provider)
                agent_model = agent.model if agent.model != "default" else (model or agent.model)

                # Get timeout from config (default 180s = 3 min)
                timeout_seconds = agent_config.timeout_seconds if agent_config else 180
                # Get max_tokens from config (default 4096)
                max_tokens = agent_config.max_tokens if agent_config else 4096

                # Get API key for this agent's provider
                agent_api_key = None
                if api_keys and agent_provider:
                    agent_api_key = api_keys.get(agent_provider.lower())

                # Get custom provider config if available
                custom_provider_config = None
                if agent_config and agent_config.custom_provider:
                    cp = agent_config.custom_provider
                    custom_provider_config = CustomProviderConfig(
                        id=cp.id,
                        name=cp.name,
                        base_url=cp.base_url,
                        api_key=cp.api_key,
                        header_name=cp.header_name,
                        header_prefix=cp.header_prefix
                    )

                # Run agent and WAIT for response before starting next agent
                # await gwarantuje, ≈ºe kolejny agent nie ruszy dop√≥ki ten nie zako≈Ñczy
                logger.info(f"‚è≥ [{idx + 1}/{len(agents_list)}] Czekam na odpowied≈∫ od agenta {agent.role}...")
                response = await self._run_agent(
                    review, project, agent, agent_provider, agent_model,
                    agent_api_key, custom_provider_config, timeout_seconds, max_tokens
                )
                agent_responses[agent.role] = response
                
                # Log what we got from agent
                if response is None:
                    logger.warning(f"‚ùå [{idx + 1}/{len(agents_list)}] Agent {agent.role} zwr√≥ci≈Ç None - brak odpowiedzi")
                elif response and response.strip().startswith(("[B≈ÅƒÑD]", "[ERROR]", "[TIMEOUT]", "[EMPTY]")):
                    logger.warning(f"‚ùå [{idx + 1}/{len(agents_list)}] Agent {agent.role} zwr√≥ci≈Ç b≈ÇƒÖd: {response[:100]}")
                else:
                    logger.info(f"‚úÖ [{idx + 1}/{len(agents_list)}] Agent {agent.role} zako≈Ñczony. Odpowied≈∫ otrzymana: {response[:100] if response else 'Brak odpowiedzi'}...")
                
                # Add delay between agents to avoid rate limiting (especially for Gemini free tier)
                # Wait 5 seconds between agents to respect rate limits (Gemini free tier is strict)
                if idx < len(agents_list) - 1:  # Don't wait after last agent
                    delay_seconds = 5.0  # Increased delay for free tier Gemini API
                    logger.info(f"‚è∏Ô∏è  Czekam {delay_seconds} sekund przed uruchomieniem nastƒôpnego agenta (aby uniknƒÖƒá rate limiting Gemini free tier)...")
                    await asyncio.sleep(delay_seconds)
                
                # Teraz mo≈ºemy przej≈õƒá do nastƒôpnego agenta (dopiero po otrzymaniu odpowiedzi i op√≥≈∫nieniu)

            # === KROK 2: Uruchom moderatora ===
            await self._run_moderator(
                review=review,
                project=project,
                agent_responses=agent_responses,
                moderator_config=typed_moderator_config,
                provider_name=provider_name,
                model=model,
                api_keys=api_keys
            )

            # Mark review as completed
            review.status = "completed"
            review.completed_at = datetime.now(timezone.utc)

            # Get total issue count and send completed event
            issue_count_stmt = select(func.count(Issue.id)).where(Issue.review_id == review_id)
            total_issues = self.session.exec(issue_count_stmt).one()
            await ws_manager.send_review_completed(review_id, total_issues)

        except Exception as e:
            logger.exception(f"Review {review_id} failed: {e}")
            # Mark review as failed
            review.status = "failed"
            review.error_message = str(e)[:2000]
            review.completed_at = datetime.now(timezone.utc)

            # Send failed event
            await ws_manager.send_review_failed(review_id, str(e)[:500])

        self.session.add(review)
        self.session.commit()
        self.session.refresh(review)

        return review

    async def _run_moderator(
        self,
        review: Review,
        project: Project,
        agent_responses: dict[str, str | None],
        moderator_config: AgentConfig | None,
        provider_name: str | None,
        model: str | None,
        api_keys: dict[str, str] | None
    ):
        """Run moderator to synthesize all agent responses into final report.

        Args:
            review: Review object
            project: Project being reviewed
            agent_responses: Dict of {role: response} (None means timeout)
            moderator_config: Moderator configuration
            provider_name: Fallback provider
            model: Fallback model
            api_keys: API keys per provider
        """
        # Check if we have any valid responses from agents
        # Filter out None, empty strings, and error messages
        error_prefixes = ["[B≈ÅƒÑD]", "[ERROR]", "[TIMEOUT]", "[EMPTY]"]
        valid_responses = {}
        logger.info(f"üîç MODERATOR: Analizowanie odpowiedzi od agent√≥w. Otrzymano {len(agent_responses)} odpowiedzi.")
        
        for role, resp in agent_responses.items():
            logger.info(f"üîç MODERATOR: Sprawdzam odpowied≈∫ od agenta {role}: {type(resp).__name__}, d≈Çugo≈õƒá: {len(str(resp)) if resp else 0}")
            
            if resp is not None and resp.strip():
                # Check if response is an error message
                resp_stripped = resp.strip()
                is_error = any(resp_stripped.startswith(prefix) for prefix in error_prefixes)
                if not is_error:
                    valid_responses[role] = resp
                    logger.info(f"‚úÖ MODERATOR: Valid response from agent {role}: {resp[:100]}...")
                else:
                    logger.info(f"‚ùå MODERATOR: Filtered out error response from agent {role}: {resp_stripped[:100]}...")
            else:
                logger.info(f"‚ö†Ô∏è MODERATOR: Agent {role} returned None or empty response (resp={repr(resp)})")
        
        logger.info(f"üìä MODERATOR: Total agent responses: {len(agent_responses)}, Valid responses: {len(valid_responses)}")
        if valid_responses:
            logger.info(f"‚úÖ MODERATOR: Valid response roles: {list(valid_responses.keys())}")
        else:
            logger.warning(f"‚ö†Ô∏è MODERATOR: BRAK PRAWID≈ÅOWYCH ODPOWIEDZI - wszystkie agenci zwr√≥cili None/b≈ÇƒÖd")
        
        # If no agents responded, return appropriate message
        if not valid_responses:
            logger.warning(f"No valid agent responses for review {review.id} - all agents failed or timed out. Total agents: {len(agent_responses)}")
            review.summary = json.dumps({
                "summary": "Nie mo≈ºna przeprowadziƒá przeglƒÖdu kodu, poniewa≈º ≈ºaden z agent√≥w nie zwr√≥ci≈Ç odpowiedzi. Wszyscy agenci przekroczyli limit czasu lub wystƒÖpi≈Ç b≈ÇƒÖd.",
                "issues": [],
                "overall_quality": "Ocena og√≥lna: nie mo≈ºna oceniƒá (brak odpowiedzi od agent√≥w)"
            }, ensure_ascii=False)
            self.session.add(review)
            self.session.commit()
            return
        
        # Build moderator prompt with all agent responses
        # Use valid_responses (already filtered) instead of agent_responses
        responses_text = ""
        valid_count = 0
        timeout_count = 0
        
        for role in ["general", "security", "performance", "style"]:
            role_name = {
                "general": "Ekspert Og√≥lny",
                "security": "Ekspert Bezpiecze≈Ñstwa",
                "performance": "Ekspert Wydajno≈õci",
                "style": "Ekspert Stylu"
            }.get(role, role.title())

            if role in valid_responses:
                valid_count += 1
                response = valid_responses[role]
                # Remove markdown code blocks before passing to moderator
                cleaned_response = response.strip()
                if cleaned_response.startswith("```json"):
                    cleaned_response = cleaned_response.replace("```json", "", 1).strip()
                if cleaned_response.startswith("```"):
                    cleaned_response = cleaned_response.replace("```", "", 1).strip()
                if cleaned_response.endswith("```"):
                    cleaned_response = cleaned_response[:-3].strip()
                
                responses_text += f"\n### {role_name}\n{cleaned_response}\n"
            else:
                timeout_count += 1
                responses_text += f"\n### {role_name} [BRAK ODPOWIEDZI]\nAgent nie odpowiedzia≈Ç w wyznaczonym czasie lub wystƒÖpi≈Ç b≈ÇƒÖd.\n"

        # CRITICAL: Double-check if we have any valid responses
        # This is a safety check - if valid_count is 0 OR valid_responses is empty, don't call moderator
        if valid_count == 0 or not valid_responses:
            logger.warning(f"üö´ MODERATOR: valid_count={valid_count}, valid_responses={len(valid_responses)} (roles: {list(valid_responses.keys())}) - NIE WYWO≈ÅUJƒò moderatora LLM!")
            logger.warning(f"üö´ MODERATOR: Review {review.id} - all agents failed or timed out. Not calling moderator LLM.")
            
            # Log all agent responses for debugging
            logger.warning(f"üîç MODERATOR DEBUG: All agent_responses:")
            for role, resp in agent_responses.items():
                logger.warning(f"  - {role}: {type(resp).__name__} = {repr(resp)[:200] if resp else 'None'}")
            
            review.summary = json.dumps({
                "summary": "Nie mo≈ºna przeprowadziƒá przeglƒÖdu kodu, poniewa≈º ≈ºaden z agent√≥w nie zwr√≥ci≈Ç odpowiedzi. Wszyscy agenci przekroczyli limit czasu lub wystƒÖpi≈Ç b≈ÇƒÖd.",
                "issues": [],
                "overall_quality": "Ocena og√≥lna: nie mo≈ºna oceniƒá (brak odpowiedzi od agent√≥w)"
            }, ensure_ascii=False)
            self.session.add(review)
            self.session.commit()
            logger.info(f"‚úÖ MODERATOR: Ustawiono summary na komunikat o braku odpowiedzi. NIE WYWO≈ÅA≈ÅEM moderatora LLM.")
            return
        
        logger.info(f"‚úÖ MODERATOR: valid_count={valid_count} > 0, valid_responses={len(valid_responses)} (roles: {list(valid_responses.keys())}) - WYWO≈ÅUJƒò moderatora LLM")

        user_prompt = f"""Odpowiedzi od agent√≥w-ekspert√≥w:

{responses_text}

ZADANIE:
Sformatuj powy≈ºsze odpowiedzi od agent√≥w w JEDEN ko≈Ñcowy raport JSON.

KRYTYCZNE ZASADY:
- Masz {valid_count} odpowiedzi od agent√≥w (zignoruj {timeout_count} oznaczone jako [BRAK ODPOWIEDZI])
- TYLKO formatuj i syntetyzuj odpowiedzi od agent√≥w - NIE analizuj kodu samodzielnie
- TYLKO zebierz problemy z odpowiedzi agent√≥w - NIE dodawaj w≈Çasnych problem√≥w
- Je≈õli w odpowiedziach agent√≥w nie ma problem√≥w, zwr√≥ƒá: {{"summary": "Kod jest poprawny, nie znaleziono problem√≥w", "issues": [], "overall_quality": "Ocena og√≥lna: dobry"}}
- Je≈õli w odpowiedziach agent√≥w sƒÖ problemy, zsyntetyzuj je i usu≈Ñ duplikaty
- Ocenƒô og√≥lnƒÖ wyznacz TYLKO na podstawie problem√≥w znalezionych przez agent√≥w

Przyk≈Çad poprawnej odpowiedzi (gdy agenci znale≈∫li problemy):
{{"summary": "Agenci znale≈∫li kilka problem√≥w: [synteza problem√≥w z odpowiedzi agent√≥w]", "issues": [synteza issues z odpowiedzi agent√≥w, bez duplikat√≥w], "overall_quality": "Ocena og√≥lna: wymaga poprawy"}}

Przyk≈Çad poprawnej odpowiedzi (gdy agenci nie znale≈∫li problem√≥w):
{{"summary": "Kod jest poprawny, nie znaleziono problem√≥w", "issues": [], "overall_quality": "Ocena og√≥lna: dobry"}}

Zwr√≥ƒá TYLKO JSON, bez dodatkowego tekstu."""

        messages = [
            LLMMessage(role="system", content=self.MODERATOR_PROMPT),
            LLMMessage(role="user", content=user_prompt)
        ]

        # Get moderator provider/model
        mod_provider = moderator_config.provider if moderator_config else provider_name
        mod_model = moderator_config.model if moderator_config else model
        mod_timeout = moderator_config.timeout_seconds if moderator_config else 300  # 5 min default for moderator
        mod_max_tokens = moderator_config.max_tokens if moderator_config else 4096  # Default 4096 for moderator

        # Get API key
        mod_api_key = None
        if api_keys and mod_provider:
            mod_api_key = api_keys.get(mod_provider.lower())

        # Custom provider for moderator
        custom_provider_config = None
        if moderator_config and moderator_config.custom_provider:
            cp = moderator_config.custom_provider
            custom_provider_config = CustomProviderConfig(
                id=cp.id,
                name=cp.name,
                base_url=cp.base_url,
                api_key=cp.api_key,
                header_name=cp.header_name,
                header_prefix=cp.header_prefix
            )

        try:
            raw_output, response_provider, response_model = await asyncio.wait_for(
                provider_router.generate(
                    messages=messages,
                    provider_name=mod_provider,
                    model=mod_model,
                    temperature=0.0,
                    max_tokens=mod_max_tokens,
                    api_key=mod_api_key,
                    custom_provider_config=custom_provider_config
                ),
                timeout=mod_timeout
            )

            # Remove markdown code block fences if present
            cleaned_output = raw_output.strip()
            if cleaned_output.startswith("```json"):
                cleaned_output = cleaned_output.replace("```json", "", 1).strip()
            if cleaned_output.startswith("```"):
                cleaned_output = cleaned_output.replace("```", "", 1).strip()
            if cleaned_output.endswith("```"):
                cleaned_output = cleaned_output[:-3].strip()
            
            # Check for placeholders BEFORE storing
            if self._contains_placeholders(cleaned_output):
                logger.warning("Moderator response contains placeholder patterns - rejecting")
                review.summary = "[B≈ÅƒÑD] Moderator zwr√≥ci≈Ç odpowied≈∫ z placeholderami zamiast rzeczywistej analizy"
                self.session.add(review)
                self.session.commit()
                return
            
            # Auto-correct overall_quality if inconsistent with issues count
            try:
                moderator_data = json.loads(cleaned_output)
                
                # Check parsed data for placeholders
                summary = moderator_data.get("summary", "")
                if self._contains_placeholders(summary):
                    logger.warning("Moderator summary contains placeholder patterns - rejecting")
                    review.summary = "[B≈ÅƒÑD] Moderator zwr√≥ci≈Ç odpowied≈∫ z placeholderami zamiast rzeczywistej analizy"
                    self.session.add(review)
                    self.session.commit()
                    return
                
                # Check issues for placeholders
                issues = moderator_data.get("issues", [])
                for issue in issues:
                    if isinstance(issue, dict):
                        title = issue.get("title", "")
                        description = issue.get("description", "")
                        if self._contains_placeholders(title) or self._contains_placeholders(description):
                            logger.warning(f"Moderator issue contains placeholder patterns - rejecting entire response")
                            review.summary = "[B≈ÅƒÑD] Moderator zwr√≥ci≈Ç odpowied≈∫ z placeholderami zamiast rzeczywistej analizy"
                            self.session.add(review)
                            self.session.commit()
                            return
                
                issues_count = len(issues)
                overall_quality = moderator_data.get("overall_quality", "")
                
                # If no issues but quality says "wymaga poprawy" or "s≈Çaby", correct it
                if issues_count == 0:
                    if "wymaga poprawy" in overall_quality.lower() or "s≈Çaby" in overall_quality.lower():
                        logger.info(f"Auto-correcting overall_quality: no issues but quality was '{overall_quality}'")
                        moderator_data["overall_quality"] = "Ocena og√≥lna: dobry"
                        cleaned_output = json.dumps(moderator_data, ensure_ascii=False)
                
                # Store cleaned version
                raw_output = cleaned_output
            except (json.JSONDecodeError, KeyError, TypeError) as e:
                logger.debug(f"Could not auto-correct overall_quality: {e}")
                # Still use cleaned output even if auto-correction failed
                raw_output = cleaned_output

            # Store moderator summary in review
            review.summary = raw_output[:50000]
            self.session.add(review)
            self.session.commit()

            # Parse and store issues from moderator response
            await self._store_moderator_issues(review, raw_output)

            logger.info(f"Moderator completed for review {review.id}")

        except asyncio.TimeoutError:
            logger.error(f"Moderator timed out for review {review.id}")
            review.summary = "[TIMEOUT] Moderator przekroczy≈Ç limit czasu"
            self.session.add(review)
            self.session.commit()

    async def _run_agent(
        self,
        review: Review,
        project: Project,
        agent: ReviewAgent,
        provider_name: str | None,
        model: str | None,
        api_key: str | None = None,
        custom_provider_config: CustomProviderConfig | None = None,
        timeout_seconds: int = 180,
        max_tokens: int = 4096
    ):
        """Run a single agent for the review with timeout handling.

        Args:
            review: Review object
            project: Project being reviewed
            agent: ReviewAgent record to update
            provider_name: LLM provider to use
            model: Model name to use
            api_key: API key for the provider (optional)
            custom_provider_config: Configuration for custom provider (optional)
            timeout_seconds: Maximum time for agent response (default 180s = 3 min)
        """
        # Send agent started event
        await ws_manager.send_agent_started(review.id, agent.role)

        # Store configured timeout
        agent.timeout_seconds = timeout_seconds

        # Build prompt
        system_prompt = self.AGENT_PROMPTS.get(agent.role, self.AGENT_PROMPTS["general"])
        user_prompt = self._build_user_prompt(project)

        messages = [
            LLMMessage(role="system", content=system_prompt),
            LLMMessage(role="user", content=user_prompt)
        ]

        async def _generate_with_cache():
            """Helper to run generation with caching logic."""
            cache_key = None
            effective_provider = custom_provider_config.id if custom_provider_config else (provider_name or settings.default_provider)
            if settings.enable_agent_caching:
                cache_key = cache.generate_llm_cache_key(
                    provider=effective_provider,
                    model=model or settings.default_model,
                    prompt=system_prompt + user_prompt,
                    temperature=0.0
                )
                cached_response = cache.get(cache_key)
                if cached_response:
                    return cached_response, effective_provider, model or settings.default_model
                else:
                    # Generate response
                    raw_out, resp_provider, resp_model = await provider_router.generate(
                        messages=messages,
                        provider_name=provider_name,
                        model=model,
                        temperature=0.0,
                        max_tokens=max_tokens,
                        api_key=api_key,
                        custom_provider_config=custom_provider_config
                    )
                    # Cache the response
                    cache.set(cache_key, raw_out)
                    return raw_out, resp_provider, resp_model
            else:
                # Generate response without caching
                return await provider_router.generate(
                    messages=messages,
                    provider_name=provider_name,
                    model=model,
                    temperature=0.0,
                    max_tokens=max_tokens,  # Use max_tokens parameter instead of hardcoded 4096
                    api_key=api_key,
                    custom_provider_config=custom_provider_config
                )

        try:
            # Run with timeout
            logger.info(f"üîÑ Agent {agent.role} ({provider_name}/{model}) - Starting generation with timeout {timeout_seconds}s...")
            raw_output, response_provider, response_model = await asyncio.wait_for(
                _generate_with_cache(),
                timeout=timeout_seconds
            )
            logger.info(f"‚úÖ Agent {agent.role} received response: provider={response_provider}, model={response_model}, length={len(raw_output) if raw_output else 0} chars")

            # Check if response is empty
            if not raw_output or not raw_output.strip():
                logger.warning(f"Agent {agent.role} returned empty response")
                agent.raw_output = "[EMPTY] Agent zwr√≥ci≈Ç pustƒÖ odpowied≈∫"
                agent.parsed_successfully = False
                agent.timed_out = False
                agent.provider = response_provider or provider_name or "unknown"
                agent.model = response_model or model or "unknown"
                
                self.session.add(agent)
                self.session.commit()
                self.session.refresh(agent)
                
                await ws_manager.send_agent_completed(
                    review.id,
                    agent.role,
                    0,
                    False
                )
                return None

            # Parse response
            parsed_successfully, issues_data = self._parse_response(raw_output)

            # Update the existing agent record - SUCCESS
            agent.provider = response_provider or provider_name or "unknown"
            agent.model = response_model or model or "unknown"
            agent.raw_output = raw_output[:50000]  # Truncate if too long
            agent.parsed_successfully = parsed_successfully
            agent.timed_out = False

            self.session.add(agent)
            self.session.commit()
            self.session.refresh(agent)

            # Send agent completed event
            await ws_manager.send_agent_completed(
                review.id,
                agent.role,
                len(issues_data),
                parsed_successfully
            )

            return raw_output  # Return response for moderator

        except asyncio.TimeoutError:
            # Agent timed out
            logger.warning(f"Agent {agent.role} timed out after {timeout_seconds}s")

            agent.timed_out = True
            agent.parsed_successfully = False
            agent.raw_output = f"[TIMEOUT] Agent przekroczy≈Ç limit czasu ({timeout_seconds} sekund)"
            agent.provider = provider_name or "unknown"
            agent.model = model or "unknown"

            self.session.add(agent)
            self.session.commit()
            self.session.refresh(agent)

            # Send agent completed event with timeout flag
            await ws_manager.send_agent_completed(
                review.id,
                agent.role,
                0,
                False
            )

            return None  # No response

        except Exception as e:
            # Handle any other errors (API errors, network errors, etc.)
            error_msg = str(e)[:500]  # Truncate error message
            error_type = type(e).__name__
            
            # Special handling for common errors
            is_rate_limit = "429" in error_msg or "Too Many Requests" in error_msg or "rate limit" in error_msg.lower()
            is_ollama_error = "Ollama" in error_type or "ollama" in error_msg.lower()
            is_value_error = error_type == "ValueError"
            
            if is_rate_limit:
                error_output = f"[B≈ÅƒÑD] Rate limiting: Przekroczono limit zapyta≈Ñ do API. Spr√≥buj ponownie za kilka minut."
                logger.warning(f"Agent {agent.role} hit rate limit (429) for provider {provider_name}. Error: {error_msg}")
            elif is_ollama_error or (is_value_error and "ollama" in error_msg.lower()):
                # Ollama-specific error messages
                if "not available" in error_msg.lower() or "is not available" in error_msg.lower():
                    error_output = f"[B≈ÅƒÑD] Ollama nie jest dostƒôpny: {error_msg}. Sprawd≈∫ czy Ollama jest uruchomiony (np. 'ollama serve')."
                elif "model" in error_msg.lower() and "not found" in error_msg.lower():
                    error_output = f"[B≈ÅƒÑD] Model Ollama nie zosta≈Ç znaleziony: {error_msg}. Sprawd≈∫ dostƒôpne modele (np. 'ollama list')."
                elif "timeout" in error_msg.lower():
                    error_output = f"[B≈ÅƒÑD] Ollama timeout: Przekroczono limit czasu ({timeout_seconds}s). Model mo≈ºe potrzebowaƒá wiƒôcej czasu lub Ollama nie odpowiada."
                else:
                    error_output = f"[B≈ÅƒÑD] Ollama b≈ÇƒÖd: {error_msg}"
                logger.error(f"ü¶ô Agent {agent.role} - Ollama error: {error_type}: {error_msg}", exc_info=True)
            else:
                error_output = f"[B≈ÅƒÑD] {error_type}: {error_msg}"
            
            logger.error(f"Agent {agent.role} ({provider_name}/{model}) failed with error: {error_type}: {error_msg}", exc_info=True)

            agent.timed_out = False
            agent.parsed_successfully = False
            agent.raw_output = error_output
            agent.provider = provider_name or "unknown"
            agent.model = model or "unknown"

            logger.info(f"Saving error for agent {agent.role}: raw_output='{error_output[:100]}'")
            self.session.add(agent)
            self.session.commit()
            self.session.refresh(agent)
            logger.info(f"Agent {agent.role} saved with raw_output length: {len(agent.raw_output) if agent.raw_output else 0}")

            # Send agent completed event with error flag
            await ws_manager.send_agent_completed(
                review.id,
                agent.role,
                0,
                False
            )

            # Return error message instead of None, so it can be logged/filtered by moderator
            # Moderator will filter out responses starting with [B≈ÅƒÑD] etc.
            return error_output

    async def _store_moderator_issues(self, review: Review, summary_text: str | None):
        """Parse moderator JSON summary and store issues for council review."""
        if not summary_text:
            logger.warning("Council summary missing - no issues stored")
            return

        # Check for placeholder patterns before parsing
        if self._contains_placeholders(summary_text):
            logger.warning("Moderator response contains placeholder patterns - rejecting")
            review.summary = "[B≈ÅƒÑD] Moderator zwr√≥ci≈Ç odpowied≈∫ z placeholderami zamiast rzeczywistej analizy"
            self.session.add(review)
            self.session.commit()
            return

        # Remove markdown code block fences if present
        cleaned_text = summary_text.strip()
        if cleaned_text.startswith("```json"):
            cleaned_text = cleaned_text.replace("```json", "", 1).strip()
        if cleaned_text.startswith("```"):
            cleaned_text = cleaned_text.replace("```", "", 1).strip()
        if cleaned_text.endswith("```"):
            cleaned_text = cleaned_text[:-3].strip()

        try:
            data = json.loads(cleaned_text)
        except json.JSONDecodeError as e:
            logger.error(f"Council summary is not valid JSON - no issues stored. Error: {e}")
            logger.debug(f"Cleaned text preview: {cleaned_text[:500]}...")
            return

        issues = data.get("issues", [])
        if not isinstance(issues, list):
            logger.error("Council summary issues is not a list - no issues stored")
            return

        # Remove any existing issues for this review before storing moderator issues
        existing_issues = self.session.exec(select(Issue).where(Issue.review_id == review.id)).all()
        for issue in existing_issues:
            self.session.delete(issue)
        self.session.commit()

        for issue_data in issues:
            description = (issue_data.get("description") or "").strip()
            title = description.split(".")[0][:120] if description else "Zg≈Çoszony problem"

            issue = Issue(
                review_id=review.id,
                file_id=None,
                severity=issue_data.get("severity", "info"),
                category=issue_data.get("category", "style"),
                title=title,
                description=description,
                file_name=issue_data.get("file_name"),
                line_start=issue_data.get("line_start"),
                line_end=issue_data.get("line_end")
            )
            self.session.add(issue)
            self.session.commit()
            self.session.refresh(issue)

            suggested_code = issue_data.get("suggested_code")
            if suggested_code:
                suggestion = Suggestion(
                    issue_id=issue.id,
                    suggested_code=suggested_code,
                    explanation="Suggested fix from moderator"
                )
                self.session.add(suggestion)
                self.session.commit()

    def _build_user_prompt(self, project: Project) -> str:
        """Build user prompt with project code.

        Args:
            project: Project being reviewed

        Returns:
            Formatted prompt string
        """
        # Get all files for the project
        from sqlmodel import select
        statement = select(File).where(File.project_id == project.id).limit(20)
        files = self.session.exec(statement).all()

        # Build prompt
        prompt = f"""Proszƒô przejrzyj nastƒôpujƒÖcy projekt: {project.name}

Opis: {project.description or "Brak opisu"}

Pliki ({len(files)}):

"""

        for file in files:
            # Truncate very long files
            content = file.content
            if len(content) > 5000:
                content = content[:5000] + "\n... (obciƒôte)"

            prompt += f"""
---
Plik: {file.name}
Jƒôzyk: {file.language or "nieznany"}

```
{content}
```

"""

        prompt += """
Przeanalizuj ten kod i zwr√≥ƒá swoje uwagi TYLKO w formacie JSON (bez dodatkowego tekstu, bez markdown code blocks):

{
  "issues": [
    {
      "severity": "info",
      "category": "security",
      "title": "Tytu≈Ç problemu po polsku",
      "description": "Opis problemu po polsku",
      "file_name": "nazwa_pliku.ext",
      "line_start": 10,
      "line_end": 15,
      "code_snippet": "fragment kodu",
      "suggested_fix": "Sugestia poprawki po polsku"
    }
  ],
  "summary": "Podsumowanie analizy po polsku"
}

WA≈ªNE:
- Przeanalizuj kod i znajd≈∫ PRAWDZIWE problemy
- Wype≈Çnij wszystkie pola PRAWDZIWYMI danymi z analizy
- Je≈õli nie ma problem√≥w, zwr√≥ƒá: {"issues": [], "summary": "Nie znaleziono problem√≥w"}
- Wszystkie teksty muszƒÖ byƒá po polsku
- Zwr√≥ƒá TYLKO JSON, bez markdown, bez dodatkowego tekstu, bez ```json ani ```"""

        return prompt

    def _contains_placeholders(self, text: str) -> bool:
        """Check if text contains placeholder patterns that should be rejected.
        
        Args:
            text: Text to check
            
        Returns:
            True if placeholders detected
        """
        if not text or len(text.strip()) < 10:
            return False  # Too short to be a real placeholder issue
        
        text_lower = text.lower()
        
        # Strong indicators - these are almost certainly placeholders
        strong_patterns = [
            "po polsku",  # Must be exact phrase
            "wype≈Çnij",
            "kr√≥tki tytu≈Ç",
            "szczeg√≥≈Çowy opis",
            "opcjonalne podsumowanie",
            "og√≥lne podsumowanie przeglƒÖdu kodu",
            "sugestia naprawy po polsku",
            "opcjonalna sugestia poprawki po polsku",
            "| \"warning\" | \"error\"",  # Example syntax from prompts
            "\"info\" | \"warning\"",  # Example syntax
            "rzeczywisty tytu≈Ç problemu",  # Full phrase from prompt
            "rzeczywiste podsumowanie przeglƒÖdu kodu",  # Full phrase from prompt
            "szczeg√≥≈Çowy opis znalezionego problemu po polsku",  # Full phrase from prompt
        ]
        
        for pattern in strong_patterns:
            if pattern in text_lower:
                return True
        
        # Weak indicators - check context (must appear in suspicious context)
        weak_patterns = [
            ("rzeczywisty", ["tytu≈Ç", "problem", "podsumowanie", "opis"]),
            ("rzeczywiste", ["podsumowanie", "dane"]),
        ]
        
        for word, context_words in weak_patterns:
            if word in text_lower:
                # Check if it appears with context words that suggest it's from a prompt
                for ctx in context_words:
                    if ctx in text_lower:
                        # Check proximity - if they're close together, it's likely a placeholder
                        word_pos = text_lower.find(word)
                        ctx_pos = text_lower.find(ctx)
                        if word_pos != -1 and ctx_pos != -1:
                            distance = abs(word_pos - ctx_pos)
                            if distance < 50:  # Words are close together
                                return True
        
        return False

    def _parse_response(self, raw_output: str) -> tuple[bool, list[dict]]:
        """Parse LLM response into issues.

        Args:
            raw_output: Raw LLM output

        Returns:
            Tuple of (success, issues_list)
        """
        # Check for placeholder patterns first
        if self._contains_placeholders(raw_output):
            logger.warning("Response contains placeholder patterns - rejecting")
            return False, []
        
        # Remove markdown code block fences if present
        cleaned_output = raw_output.strip()
        if cleaned_output.startswith("```json"):
            cleaned_output = cleaned_output.replace("```json", "", 1).strip()
        if cleaned_output.startswith("```"):
            cleaned_output = cleaned_output.replace("```", "", 1).strip()
        if cleaned_output.endswith("```"):
            cleaned_output = cleaned_output[:-3].strip()
        
        try:
            # Try to parse as JSON
            data = json.loads(cleaned_output)
            
            # Check parsed data for placeholders
            if isinstance(data, dict):
                summary = data.get("summary", "")
                if self._contains_placeholders(summary):
                    logger.warning("Summary contains placeholder patterns - rejecting")
                    return False, []
                
                issues = data.get("issues", [])
                for issue in issues:
                    if isinstance(issue, dict):
                        title = issue.get("title", "")
                        description = issue.get("description", "")
                        if self._contains_placeholders(title) or self._contains_placeholders(description):
                            logger.warning("Issue contains placeholder patterns - rejecting")
                            return False, []
            schema = ReviewResponseSchema(**data)
            issues_data = [issue.model_dump() for issue in schema.issues]
            return True, issues_data

        except json.JSONDecodeError as e:
            logger.warning(f"JSON decode error in LLM response: {str(e)[:200]}")
            logger.debug(f"Raw output preview: {raw_output[:500]}...")

            # Fallback: try to extract JSON from text (already cleaned, but try regex)
            try:
                # Look for JSON block
                import re
                json_match = re.search(r'\{[\s\S]*\}', raw_output)
                if json_match:
                    data = json.loads(json_match.group(0))
                    schema = ReviewResponseSchema(**data)
                    issues_data = [issue.model_dump() for issue in schema.issues]
                    logger.info("Successfully recovered JSON from text")
                    return True, issues_data
            except Exception as fallback_error:
                logger.error(f"Fallback parsing also failed: {str(fallback_error)[:200]}")

        except ValidationError as e:
            logger.error(f"Pydantic validation error in LLM response: {e.errors()}")
            logger.debug(f"Raw output preview: {raw_output[:500]}...")

        # Parsing failed
        logger.error("Failed to parse LLM response after all attempts")
        return False, []

    async def _store_issue(self, review: Review, issue_data: dict):
        """Store an issue in the database.

        Args:
            review: Review object
            issue_data: Issue data dictionary
        """
        # Find file_id if file_name is provided
        file_id = None
        if issue_data.get("file_name"):
            from sqlmodel import select
            statement = select(File).where(
                File.project_id == review.project_id,
                File.name == issue_data["file_name"]
            )
            file = self.session.exec(statement).first()
            if file:
                file_id = file.id

        # Create issue
        issue = Issue(
            review_id=review.id,
            file_id=file_id,
            severity=issue_data["severity"],
            category=issue_data["category"],
            title=issue_data["title"],
            description=issue_data["description"],
            file_name=issue_data.get("file_name"),
            line_start=issue_data.get("line_start"),
            line_end=issue_data.get("line_end")
        )
        self.session.add(issue)
        self.session.commit()
        self.session.refresh(issue)

        # Create suggestion if provided
        if issue_data.get("suggested_fix"):
            suggestion = Suggestion(
                issue_id=issue.id,
                suggested_code=issue_data["suggested_fix"],
                explanation="Suggested fix from code review agent"
            )
            self.session.add(suggestion)
            self.session.commit()
